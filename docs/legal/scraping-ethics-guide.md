# Ethical Web Scraping Guide

## ğŸ¯ Core Principles

### 1. Transparency
- **Identify Yourself:** Always use descriptive User-Agent headers
- **Provide Contact:** Include email and website in User-Agent
- **State Purpose:** Clear about why you're collecting data
- **Public Documentation:** Maintain public page about data collection

### 2. Respect
- **Follow robots.txt:** Always check and comply
- **Honor Rate Limits:** Never overwhelm servers
- **Respect Business Hours:** Avoid peak traffic times
- **Check Terms of Service:** Review and comply with ToS

### 3. Responsibility
- **Data Minimization:** Only collect what you need
- **Secure Storage:** Protect collected data
- **Accurate Representation:** Don't misrepresent data
- **Attribution:** Always credit sources

## ğŸ“‹ Pre-Scraping Checklist

### Legal Review
```
âœ“ Is the data publicly accessible?
âœ“ Have you reviewed the Terms of Service?
âœ“ Does robots.txt allow your intended access?
âœ“ Is there an API available instead?
âœ“ Have you checked for copyright restrictions?
âœ“ Do you need explicit consent?
```

### Technical Review
```
âœ“ Have you implemented rate limiting?
âœ“ Is your User-Agent transparent?
âœ“ Are you handling errors gracefully?
âœ“ Do you have retry logic with backoff?
âœ“ Are you caching to avoid repeat requests?
âœ“ Have you tested on a small scale first?
```

### Ethical Review
```
âœ“ Is there a legitimate purpose?
âœ“ Could this harm the website owner?
âœ“ Are you being transparent about usage?
âœ“ Would you be comfortable if roles were reversed?
âœ“ Have you considered the server load impact?
âœ“ Is the data being used responsibly?
```

## ğŸš¦ Decision Framework

### Green Light (Proceed)
- âœ… Public government data
- âœ… Open data with clear licensing
- âœ… Explicit permission granted
- âœ… API available and accessible
- âœ… robots.txt allows access
- âœ… Terms of Service permit scraping

### Yellow Light (Proceed with Caution)
- âš ï¸ No explicit prohibition
- âš ï¸ Rate limits not specified
- âš ï¸ Terms unclear
- âš ï¸ High-traffic website
- âš ï¸ Personal data involved
- âš ï¸ Commercial website

### Red Light (Do Not Proceed)
- âŒ robots.txt disallows
- âŒ Terms prohibit scraping
- âŒ Authentication required
- âŒ Personal/sensitive data
- âŒ Copyright protected content
- âŒ Could cause harm

## ğŸ›  Best Practices

### Rate Limiting Strategy
```javascript
// Recommended approach
const rateLimits = {
  'government-sites': 2,    // 2 requests per second
  'council-sites': 1,        // 1 request per second
  'commercial-sites': 0.5,   // 1 request per 2 seconds
  'high-traffic': 0.1        // 1 request per 10 seconds
};

// Implement exponential backoff
const backoffStrategy = {
  initial: 1000,      // 1 second
  multiplier: 2,      // Double each retry
  maximum: 60000,     // Max 1 minute
  jitter: true        // Add randomness
};
```

### User-Agent Format
```
BotName/Version (+https://website.com; purpose; contact@email.com)

Examples:
NWLondonLedger/1.0 (+https://nwlondonledger.com; Public Data Aggregation; legal@nwlondonledger.com)
PropertyBot/2.0 (+https://example.com/bot-info; Research; bot@example.com) Mozilla/5.0 compatible
```

### Robots.txt Compliance
```javascript
// Always check before scraping
async function canScrape(url) {
  const robotsTxt = await fetchRobotsTxt(url);
  const parser = new RobotsParser(robotsTxt);

  return parser.isAllowed(url, 'NWLondonLedger');
}

// Honor crawl-delay
const crawlDelay = parser.getCrawlDelay('NWLondonLedger');
if (crawlDelay) {
  await sleep(crawlDelay * 1000);
}
```

## ğŸ“Š Data Collection Ethics

### What TO Collect
- âœ… Publicly displayed information
- âœ… Factual data (prices, dates, addresses)
- âœ… Government published data
- âœ… Business information (opening hours, services)
- âœ… Already aggregated statistics

### What NOT to Collect
- âŒ Personal contact information
- âŒ Private user data
- âŒ Password-protected content
- âŒ Copyrighted creative works
- âŒ Competitive intelligence
- âŒ Data behind paywalls

### Data Handling
1. **Storage:** Secure and encrypted
2. **Retention:** Only as long as necessary
3. **Sharing:** Never sell or misuse
4. **Accuracy:** Regular updates and corrections
5. **Deletion:** Honor removal requests

## ğŸ” Source-Specific Guidelines

### Government Websites (.gov.uk)
- Generally permissible under OGL
- Respect rate limits
- Provide attribution
- Check specific department policies

### Council Websites
- Planning data is public record
- Respect server resources
- Consider FOI for bulk data
- Contact for permission if unclear

### Commercial Sites
- Always check Terms of Service
- Prefer official APIs
- Consider licensing agreements
- Respect competitive boundaries

### Personal Websites/Blogs
- Seek explicit permission
- Respect copyright
- Minimal extraction
- Always attribute

## ğŸ“ Documentation Requirements

### Maintain Records Of
1. **Consent:** Permission emails/agreements
2. **Compliance:** robots.txt checks, ToS reviews
3. **Purpose:** Why data was collected
4. **Source:** Where data came from
5. **Timestamp:** When collected
6. **Method:** How it was collected

### Transparency Report Template
```markdown
# Data Collection Transparency Report

## Sources
- Domain: example.com
- Data Type: Public property listings
- Collection Method: API / Web scraping
- Frequency: Daily at 3am UTC
- Rate Limit: 1 req/second

## Compliance
- robots.txt: âœ… Checked and compliant
- Terms of Service: âœ… Reviewed [date]
- Consent: âœ… Implicit/Explicit
- Attribution: "Data from Example.com"

## Purpose
- Aggregate public property information
- Provide free access to residents
- Non-commercial use

## Contact
- Our Bot: BotName/1.0
- Email: contact@oursite.com
- Opt-out: Send request to legal@oursite.com
```

## ğŸš¨ Warning Signs

### Stop Immediately If
- ğŸ›‘ You receive a cease and desist
- ğŸ›‘ The site implements anti-scraping measures
- ğŸ›‘ You're causing performance issues
- ğŸ›‘ Terms of Service change to prohibit
- ğŸ›‘ You receive 429 (Too Many Requests) errors
- ğŸ›‘ The site owner requests you stop

### Response Protocol
1. **Stop** all scraping immediately
2. **Document** the issue
3. **Respond** professionally within 24 hours
4. **Review** your practices
5. **Adjust** approach if needed
6. **Seek** legal advice if necessary

## ğŸ“š Resources

### Tools
- [robots.txt Checker](https://example.com)
- [Terms of Service Analyzer](https://example.com)
- [Rate Limit Calculator](https://example.com)

### Legal Resources
- [ICO Guidance](https://ico.org.uk)
- [CMA Scraping Guidance](https://www.gov.uk/cma)
- [Open Government License](https://www.nationalarchives.gov.uk/doc/open-government-licence/)

### Industry Standards
- [robots.txt Specification](https://www.robotstxt.org)
- [Ethical Web Scraping](https://blog.apify.com/web-scraping-ethics/)
- [Data Collection Best Practices](https://example.com)

## âœ… Ethical Certification

By following this guide, you commit to:
- Transparent identification
- Respectful rate limiting
- Legal compliance
- Responsible data use
- Prompt response to concerns
- Continuous improvement

---

**Document Version:** 1.0
**Last Updated:** January 2024
**Next Review:** Quarterly
**Contact:** ethics@nwlondonledger.com